{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbaa67-f946-4f55-9e43-a881c55944d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# time.sleep(60*60*24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ca8a0e",
   "metadata": {},
   "source": [
    "This notebook must be run twice per topic, one with LANG='english', one with LANG='other_languages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b15fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import get_path_collected, get_path_urlsinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0304b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME=\"COVID-19\"\n",
    "# PROJECT_NAME='Climate change'\n",
    "# PROJECT_NAME='Biology_sample'\n",
    "# PROJECT_NAME='History_sample'\n",
    "# PROJECT_NAME='Media_sample'\n",
    "\n",
    "LANG='english'\n",
    "# LANG='other_languages'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483acd82-0fd4-4c14-bcd6-07fe0ecdccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import tldextract\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from copy import deepcopy\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf2064e-9a5d-49ed-b7f7-3a90baf43bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_collection import get_current_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3f23a3-604c-48e9-9157-1b8cf59312a9",
   "metadata": {},
   "source": [
    "# Load sources revision info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ba8a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INPUT=get_path_collected(PROJECT_NAME, LANG)\n",
    "PATHNAME_INPUT=PATH_INPUT+'sources_storage.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eeef9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHNAME_INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a9842e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUTPUT=get_path_urlsinfo()\n",
    "PATHNAME_OUTPUT=PATH_OUTPUT+'urls_info.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189218b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHNAME_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a789c00f-a3d2-4417-997b-2d65554c16f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _URLS_REV=pd.read_csv(PATHNAME_INPUT, usecols=['source_use','source_type','source','page'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8399eaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS_REV=pd.read_csv(PATHNAME_INPUT, usecols=['page','source_id_i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d43c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS_REV=_URLS_REV.drop_duplicates(subset='source_id_i')\n",
    "_URLS_REV=_URLS_REV.dropna(subset=['source_id_i'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a995358",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS_REV['source_type']=_URLS_REV['source_id_i'].map(lambda x: x.split('|$|')[-2])\n",
    "_URLS_REV['source']     =_URLS_REV['source_id_i'].map(lambda x: x.split('|$|')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8901832",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS_REV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45190c93-879b-43ad-a4d0-9a1c71d469f5",
   "metadata": {},
   "source": [
    "Brief statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12c3c0c-558d-483d-9b54-fddf5980c93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _URLS_REV.drop_duplicates(subset=['source_use','source_type','source']).source_type.value_counts(normalize=True)*100\n",
    "_URLS_REV.drop_duplicates(subset=['source_type','source']).source_type.value_counts(normalize=True)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa34d0b6-a344-43b9-8e58-6e1d2b09b21e",
   "metadata": {},
   "source": [
    "#### Extract unique urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897338a3-7987-486e-b7a8-269e26d20b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_URLS_REV=_URLS_REV[~_URLS_REV.source_type.isin(['isbn','issn','title','citeq'])]\n",
    "\n",
    "_URLS_REV['url']= _URLS_REV['source_type'].map(lambda x: 'https://doi.org/' if x=='doi' else '')\n",
    "_URLS_REV['url']+=_URLS_REV['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fab154e-35c5-4bc8-8a84-d0d8c1c98415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _URLS_REV['url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b0a6f9-1fb7-4cc2-a24e-73e97fc71a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS=_URLS_REV.drop_duplicates(subset=['url'])['url'].values\n",
    "# URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2e0f3-0a35-4b9b-a420-647d4570925a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found {len(URLS)} unique urls, out of\", len(_URLS_REV.page.unique()),\"pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb33d89-a576-47a6-95a7-a20cb68c49f7",
   "metadata": {},
   "source": [
    "# Load previously scanned urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f55a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHNAME_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c2404-fcdd-48df-80b2-391a4d0fe13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ALREADY_SCANNED_URLS=set(pd.read_csv(PATHNAME_OUTPUT, usecols=['url']).url.values)\n",
    "except:\n",
    "    ALREADY_SCANNED_URLS=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42efbf31-a7a9-4d93-9f20-e38d3b9146b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"already scanned urls:\",len(ALREADY_SCANNED_URLS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "947e3950",
   "metadata": {},
   "source": [
    "#### Remove previously scanned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c38a24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS=[u for u in URLS if u not in ALREADY_SCANNED_URLS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1deab95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"remaining urls to scan:\", len(URLS))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0789d3",
   "metadata": {},
   "source": [
    "# Batch of urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d4acee",
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE_BATCH=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "URLS_BATCHES = [URLS[i*SIZE_BATCH:(i+1)*SIZE_BATCH] for i in range((len(URLS)+SIZE_BATCH-1)//SIZE_BATCH)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5978bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of batches:\", len(URLS_BATCHES))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce2c873",
   "metadata": {},
   "source": [
    "# Retrieving destination url and url info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f157ba-0519-4aad-9f92-916b841bfeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFO_DICT={\n",
    "    'status_code':'ph',\n",
    "    'reason':'ph',\n",
    "    'timestamp_query': 'ph',\n",
    "    'destination_url':'ph',\n",
    "    'flags':'ph',\n",
    "    # 'domain':'ph',\n",
    "    # 'subdomain':'ph',\n",
    "    # 'destination_domain':'ph',\n",
    "    # 'destination_subdomain':'ph'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2576822-f31f-4958-8a0b-63f5f1214fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB this also catches keybord interrupt \n",
    "# SO PROCESS CAN'T BE STOPPED\n",
    "\n",
    "def request_url_info(url):\n",
    "    # print(url, end=' \\n  ----> ')\n",
    "    try:        \n",
    "        response=requests.get(url, timeout=10)\n",
    "        response.raise_for_status()\n",
    "        # print(response.reason, response.status_code, response.url)\n",
    "        status_code=response.status_code  \n",
    "        reason     =response.reason\n",
    "        destination_url     =response.url\n",
    "        # print(t_info['destination_url'] )\n",
    "    except requests.exceptions.MissingSchema as e:\n",
    "        status_code=\"FAILED\"  \n",
    "        reason     =\"InvalidUrl\"\n",
    "        destination_url='FAILED'\n",
    "        # print(\"Invalid URL\")\n",
    "    except requests.exceptions.SSLError as e:\n",
    "        status_code=\"FAILED\"  \n",
    "        reason     =\"SSLERrror\"\n",
    "        destination_url='FAILED'\n",
    "        # print(\"SSL Error\")\n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        status_code=response.status_code  \n",
    "        reason     =response.reason\n",
    "        destination_url=response.url\n",
    "        # print(\"Http Error\")\n",
    "    except requests.exceptions.Timeout as e:\n",
    "        status_code=\"FAILED\" \n",
    "        reason     =\"Timeout\"\n",
    "        destination_url='FAILED'\n",
    "        # print(\"Timeout Error\")\n",
    "    except requests.exceptions.ConnectionError as e:\n",
    "        status_code=\"FAILED\" \n",
    "        reason     =\"ConnectionError\"\n",
    "        destination_url='FAILED'\n",
    "        # print(\"Connection Error\")\n",
    "    except:\n",
    "        status_code=\"FAILED\" \n",
    "        reason     =\"UnknownError\"\n",
    "        destination_url='FAILED'\n",
    "        # print(\"Unknown Error\")\n",
    "    # print(\"  \",status_code, reason, destination_url)\n",
    "    return status_code, reason, destination_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6473e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHNAME_OUTPUT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6344c7e4",
   "metadata": {},
   "source": [
    "Only failure I have seen of the code below, is when connection is estabilished but the page keeps sending content indefinitely. Ref. https://github.com/psf/requests/issues/1577. If this happends one can stop kernel, and this will send request_url_info to the default except case (UnknownError) and will then carry on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68262762-3a74-4b57-98c4-ee76584c612f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADDED_COUNTER=0\n",
    "\n",
    "for n_b, b_urls in tqdm(enumerate(URLS_BATCHES), total=len(URLS_BATCHES)):\n",
    "    b_urls_info={}\n",
    "    \n",
    "    for url in b_urls:\n",
    "        ADDED_COUNTER+=1\n",
    "        print(f\"ADDED_COUNTER: {ADDED_COUNTER}\", end='\\r')\n",
    "        t_info=deepcopy(INFO_DICT)\n",
    "        t_info['timestamp_query']=get_current_time()\n",
    "        ############################################################ STATUS INFO AND REDIRECT\n",
    "        status_code, reason, destination_url=request_url_info(url)\n",
    "        t_info['status_code']=status_code\n",
    "        t_info['reason']=reason\n",
    "        t_info['destination_url']=destination_url\n",
    "        b_urls_info[url]=t_info\n",
    "        \n",
    "    b_urls_info_df=pd.DataFrame.from_dict(b_urls_info, orient='index').reset_index().rename(columns={'index':'url'})\n",
    "    mode, header='a', False\n",
    "    if len(ALREADY_SCANNED_URLS)==0 and n_b==0: \n",
    "        mode, header='w', True #<--- only adds header if file was non existent and this is the first batch\n",
    "    b_urls_info_df.to_csv(PATHNAME_OUTPUT, index=False, header=header, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169127c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeb9b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
