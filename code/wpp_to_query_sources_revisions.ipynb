{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2bc880",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import get_path_wpp, get_path_collected\n",
    "\n",
    "import tracemalloc as tmall\n",
    "tmall.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e08f8ec-df90-4898-a525-c261d773f621",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils_collection as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d92a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NAME=\"Climate change\"\n",
    "# PROJECT_NAME=\"COVID-19\"\n",
    "\n",
    "# PROJECT_NAME='Media_sample'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000df6f5",
   "metadata": {},
   "source": [
    "when running, make sure this date and suffix is consistent with the name of the file of choice. \n",
    "\n",
    "inside data/collected/ are the files for pages, which this notebook takes as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc8809",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#---------- for climate change\n",
    "WPP_DATE='2023-08-16'\n",
    "\n",
    "#---------- for covid-19\n",
    "# WPP_DATE='2023-09-18'\n",
    "\n",
    "#---------- for topicwise all/sample\n",
    "# WPP_DATE='2024-01-22'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b010d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROCESS_EN=True\n",
    "PROCESS_OT=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98851dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_INPUT=get_path_wpp(PROJECT_NAME)\n",
    "\n",
    "PATHNAME_INPUT=f'{PATH_INPUT}project_pages_{WPP_DATE}.csv'\n",
    "PATHNAME_INPUT=f'{PATH_INPUT}project_pages_{WPP_DATE}_sample10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479c68d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATHNAME_INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd43eddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUTPUT=get_path_wpp(PROJECT_NAME)+'{}/' #<--- will be filled with language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd20b00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64258b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETURN_ALL_REVISIONS=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2429909",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RUN=False\n",
    "\n",
    "SUFFIX=''\n",
    "\n",
    "SAMPLE_PERCENTAGE=1\n",
    "\n",
    "# SUFFIX+='_'+str(SAMPLE_PERCENTAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e645e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_RUN:\n",
    "    PATH_OUTPUT+='sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b925e2b-b668-45c0-a44c-ceec7160f004",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.SOURCE_STORAGE=True\n",
    "ut.SOURCE_STORAGE_COUNT_ONE_PER_LOCAL_CALL=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e3bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.RUN_EXPLORE_LANG_TEMPLATES=True\n",
    "ut.RUN_EXPLORE_LANG_NOSOURCE_REF_TEXT=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c627558c-fb6f-4beb-8a74-158f8ae4693c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.RUN_TEST_ALL=False\n",
    "\n",
    "ut.RUN_TEST_NOSOURCE_REF_TEXT=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6fbfd-3d22-49ea-97a1-745e8cb747a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3308d654-e418-4021-955a-654c9d1e1aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install urlextract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ba6587-ac5f-441c-ba5a-09b10148cef4",
   "metadata": {},
   "source": [
    "# Loading Project related pages (all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67de1a-41c7-4ae9-86b8-4e330b87955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WPP_PAGES=pd.read_csv(PATHNAME_INPUT)\n",
    "WPP_PAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3e7b13-a315-4c3e-92ec-77eedd44b171",
   "metadata": {},
   "source": [
    "### Selecting pages of article (by namespace 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f0b22-a0ae-4c3d-84e6-74420e1c8850",
   "metadata": {},
   "outputs": [],
   "source": [
    "WPP_PAGES=WPP_PAGES[WPP_PAGES.ns==0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0782c01-ae9a-479d-b2a5-a8fdf72c9a2b",
   "metadata": {},
   "source": [
    "# Retrieve already queried pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae2c6ba-bff4-4fad-b9cb-fca362ae5874",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_RUN:\n",
    "    print(\"since this is a sample for testing,\") \n",
    "    print(\"the dataframe is replaced silently at every call of this notebook\")\n",
    "    EN_ALREADY_RETRIEVED_PAGES=set()\n",
    "    OT_ALREADY_RETRIEVED_PAGES=set()\n",
    "    \n",
    "else:\n",
    "    if PROCESS_EN:\n",
    "        print(\"looking for english data data in folder:\", PATH_OUTPUT.format('english'))\n",
    "        try:\n",
    "            EN_ALREADY_RETRIEVED_PAGES=set([row.lang+'$'+row.page \\\n",
    "                                            for _, row in pd.read_csv(f'{PATH_OUTPUT.format(\"english\")}pages_revdata{SUFFIX}.csv').iterrows()])\n",
    "            print(\"file found\\n\")\n",
    "        except:\n",
    "            print(\"file not found\\n\")\n",
    "            EN_ALREADY_RETRIEVED_PAGES=set()\n",
    "            \n",
    "    if PROCESS_OT:\n",
    "        print(\"looking for other languages data data in folder:\", PATH_OUTPUT.format('other_languages'))\n",
    "        try:    \n",
    "            OT_ALREADY_RETRIEVED_PAGES=set([row.lang+'$'+row.page \\\n",
    "                                            for _, row in pd.read_csv(f'{PATH_OUTPUT.format(\"other_languages\")}pages_revdata{SUFFIX}.csv').iterrows()])    \n",
    "            print(\"file found\\n\")\n",
    "        except:\n",
    "            print(\"file not found\\n\")\n",
    "            OT_ALREADY_RETRIEVED_PAGES=set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71823b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"english retrieved pages:\", len(EN_ALREADY_RETRIEVED_PAGES) )\n",
    "print(\"other languages retrieved pages:\", len(OT_ALREADY_RETRIEVED_PAGES) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981595ba",
   "metadata": {},
   "source": [
    "#### Select pages for the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b89922",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_RUN:\n",
    "    SAMPLE_PAGES=WPP_PAGES.title.values[list( range(0, len(WPP_PAGES), int(100/SAMPLE_PERCENTAGE)) )]\n",
    "else:\n",
    "    SAMPLE_PAGES=WPP_PAGES.title.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6219f6c6-f29f-4f8e-b93f-1924635d9c21",
   "metadata": {},
   "source": [
    "# Extract url revisions from project pages + lang links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"data will be saved in\", PATH_OUTPUT.format(\"LANGUAGE_SPECIFIER\"))\n",
    "print(\"suffix:\", SUFFIX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec88db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132ad54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO DO\n",
    "# add page to already retrieved once has finished\n",
    "# timer whole process inside iterator\n",
    "# cleaner checkpoint saving for explore lang informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62793bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# for exploratory purposes\n",
    "# if PROCESS_EN and PROCESS_OT: _t_prefix='all'\n",
    "# if not PROCESS_EN and PROCESS_OT: _t_prefix='ot'\n",
    "# if PROCESS_EN and not PROCESS_OT: _t_prefix='en'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d7c593-858c-4d8c-904d-af3c20f69862",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "EN_ADDED_COUNTER=0\n",
    "OT_ADDED_COUNTER=0\n",
    "\n",
    "for n_page, en_page_title in enumerate(SAMPLE_PAGES):\n",
    "    main_time=time()\n",
    "    if PROCESS_EN:\n",
    "        if not f'en${en_page_title}' in EN_ALREADY_RETRIEVED_PAGES:\n",
    "            en_t_start=time()\n",
    "            ALL_DATA =ut.get_sources_revisions(en_page_title, 'en', return_all_revisions=RETURN_ALL_REVISIONS,\n",
    "                                               verbose=True, \n",
    "                                               verbose_prefix=f\"------------{n_page+1:>4d} of {len(SAMPLE_PAGES)} \")\n",
    "\n",
    "            mode, header='a', False\n",
    "            if n_page==0 and not len(EN_ALREADY_RETRIEVED_PAGES):\n",
    "                mode, header='w', True\n",
    "            ut.save_rv_data(ALL_DATA, PATH_OUTPUT.format('english'), SUFFIX, mode, header)\n",
    "            EN_ADDED_COUNTER+=1    \n",
    "            ut._update_timer('___pipeline_english', en_t_start)\n",
    "            EN_ALREADY_RETRIEVED_PAGES.update([f'en${en_page_title}'])\n",
    "            print()\n",
    "\n",
    "    if PROCESS_OT:\n",
    "        ot_t_start=time()\n",
    "        LL_DATA=ut.get_language_links_data(en_page_title)\n",
    "        for n_ll, ll in enumerate(LL_DATA):\n",
    "            LANG=ll['lang']\n",
    "            PAGE=ll['*']\n",
    "            \n",
    "            if f'{LANG}${PAGE}' in OT_ALREADY_RETRIEVED_PAGES: continue\n",
    "\n",
    "            ALL_DATA =ut.get_sources_revisions(PAGE, LANG, return_all_revisions=RETURN_ALL_REVISIONS,\n",
    "                                               verbose=True, \n",
    "                                               verbose_prefix=f\"{n_ll+1:>3} of {len(LL_DATA):<3} ({n_page+1:>4d} of {len(SAMPLE_PAGES)})\")\n",
    "\n",
    "            mode, header='a', False\n",
    "            if n_page==0 and n_ll==0 and not len(OT_ALREADY_RETRIEVED_PAGES):\n",
    "                mode, header='w', True\n",
    "            ut.save_rv_data(ALL_DATA, PATH_OUTPUT.format('other_languages'), SUFFIX, mode, header)\n",
    "            OT_ADDED_COUNTER+=1    \n",
    "            print('\\n next ll...', end='\\r')\n",
    "            OT_ALREADY_RETRIEVED_PAGES.update([f'{LANG}${PAGE}'])\n",
    "\n",
    "        ut._update_timer('___pipeline_other_languages', ot_t_start)\n",
    "\n",
    "#         for exploratory purposes\n",
    "# #     if n_page%10==0:\n",
    "#     if ut.RUN_EXPLORE_LANG_TEMPLATES:\n",
    "#         with open(f'../data/explore_lang/{_t_prefix}_lang_template_data{SUFFIX}_new.pickle', 'wb') as handle:\n",
    "#             pickle.dump(ut.EXPLORE_LANG_TEMPLATES, handle)\n",
    "\n",
    "#     if ut.RUN_EXPLORE_LANG_NOSOURCE_REF_TEXT:    \n",
    "#         with open(f'../data/explore_lang/{_t_prefix}_lang_nosource_ref_text{SUFFIX}_new.pickle', 'wb') as handle:\n",
    "#             pickle.dump(ut.EXPLORE_LANG_NOSOURCE_REF_TEXT, handle)\n",
    "        \n",
    "    ut._update_timer('whole_process', main_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98523bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.N_RESPONSE_EXCEPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd964b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.N_RESPONSE_EXCEPTIONS_LL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9580fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "OT_ADDED_COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b87ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EN_ADDED_COUNTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d75c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.GLOBAL_COUNT_RETAINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4084d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.GLOBAL_COUNT_RETAINED/(ut.GLOBAL_COUNT_SKIPPED+ut.GLOBAL_COUNT_RETAINED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e2f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "def sizeof_fmt(num, suffix='B'):\n",
    "    ''' by Fred Cirera,  https://stackoverflow.com/a/1094933/1870254, modified'''\n",
    "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
    "        if abs(num) < 1024.0:\n",
    "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
    "        num /= 1024.0\n",
    "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
    "\n",
    "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in list(\n",
    "                          locals().items())), key= lambda x: -x[1])[:10]:\n",
    "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd52a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.dir_performance(normalize='whole_process') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233344d1",
   "metadata": {},
   "source": [
    "### Saving exploration results (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e42fc4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# if PROCESS_EN and PROCESS_OT: _t_prefix='all'\n",
    "# if not PROCESS_EN and PROCESS_OT: _t_prefix='ot'\n",
    "# if PROCESS_EN and not PROCESS_OT: _t_prefix='en'\n",
    "    \n",
    "# if ut.RUN_EXPLORE_LANG_TEMPLATES:\n",
    "#     with open(f'../data/explore_lang/{_t_prefix}_lang_template_data{SUFFIX}_part_3.pickle', 'wb') as handle:\n",
    "#         pickle.dump(ut.EXPLORE_LANG_TEMPLATES, handle)\n",
    "        \n",
    "# if ut.RUN_EXPLORE_LANG_NOSOURCE_REF_TEXT:    \n",
    "#     with open(f'../data/explore_lang/{_t_prefix}_lang_nosource_ref_text{SUFFIX}_part_3.pickle', 'wb') as handle:\n",
    "#         pickle.dump(ut.EXPLORE_LANG_NOSOURCE_REF_TEXT, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe7f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load data (deserialize)\n",
    "# with open(f'../data/other_languages_template_data{SUFFIX}.pickle', 'rb') as handle:\n",
    "#     this = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf33694",
   "metadata": {},
   "source": [
    "#### Extimate parallelization limitations\n",
    "- Tracing request rate (can use utils timer and counter)\n",
    "- Tracing memory usage (can use tmall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1674c6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"request per hour (revisions):\", \\\n",
    "      ut.TEMP_COUNTERS['_request_revision_data']/(ut.TEMP_TIMERS['whole_process']/60**2),\" requests per hour\")\n",
    "print(\"request per hour (revisions+language links):\", \\\n",
    "      (ut.TEMP_COUNTERS['_request_revision_data']+ut.TEMP_COUNTERS['request_language_links'])/(ut.TEMP_TIMERS['whole_process']/60**2),\" requests per hour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc66bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, PT_MPK=tmall.get_traced_memory() \n",
    "\n",
    "print(f\" memory peak: {PT_MPK/(10**6)} Mb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf84c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "_/10**6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948f0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(ut.EXPLORE_LANG_NOSOURCE_REF_TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35d1db5",
   "metadata": {},
   "source": [
    "# Extimate by sample proportion (rough)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300125ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAMPLE_RUN:\n",
    "    print(f\"extimated total time: {ut.TEMP_TIMERS['whole_process']*100/SAMPLE_PERCENTAGE/60**2:.2f} hrs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b025f",
   "metadata": {},
   "source": [
    "# Code performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e365918",
   "metadata": {},
   "outputs": [],
   "source": [
    "ut.dir_performance(normalize='whole_process')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be70ce76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total pages analysed in this sample (english):\", len(SAMPLE_PAGES))\n",
    "print(f\"{len(SAMPLE_PAGES)/len(WPP_PAGES)*100:.2f}% of the total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e91be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total pages analysed in this sample (en+ot):\", ut.TEMP_COUNTERS['pipeline_sources'])\n",
    "# print(f\"{ut.TEMP_COUNTERS['_sources_extraction']/EXTIMATED_TOT_REVISIONS*100:.2f}% of the total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c324a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total revisions analysed in this sample (en+ot):\", ut.TEMP_COUNTERS['_sources_extraction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff05a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"total time of this sample process:\", ut.TEMP_TIMERS['whole_process']/60**2, 'hrs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5995e4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average time per page (english):\", \n",
    "      ut.TEMP_TIMERS['___pipeline_english']/(ut.TEMP_COUNTERS['___pipeline_english'])/60,\" min per page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b447e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average time per page (other_languages):\", \n",
    "      ut.TEMP_TIMERS['___pipeline_other_languages']/(ut.TEMP_COUNTERS['___pipeline_other_languages'])/60,\" min per page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694ace5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average time per revision (english+other_languages):\",\\\n",
    "      ut.TEMP_TIMERS['whole_process']/(ut.TEMP_COUNTERS['_sources_extraction']),\" seconds per revision (including request time)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3d2a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"average time TO PROCESS one revision:\", ut.TEMP_TIMERS['_sources_extraction']/(ut.TEMP_COUNTERS['_sources_extraction']),\" seconds per revision\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3cebe2",
   "metadata": {},
   "source": [
    "# Extimate by revision (if tot revision in known)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5107984",
   "metadata": {},
   "source": [
    "#### Extimate total time\n",
    "- expected_tot revisions * average revision time =expected_tot_revisions * (sample_n_revisions/sample_process_time)\n",
    "- - sample_n_revisions is given by ut.TEMP_COUNTERS(\\'_sources_extraction\\') - tracing get_sources2locations calls\n",
    "- - sample_process_time is ut.TEMP_TIMERS('whole_process') (accounting for request time as well)\n",
    "- - expected_tot_revisions: counting them in wpp_to_n_revisions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677bd4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unknown for other languages\n",
    "# EXTIMATED_TOT_REVISIONS=1483462 #manually added from results of wpp_to_n_revisions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591bc0b4",
   "metadata": {},
   "source": [
    "<!-- Can be an overextimation, since the time to process one revision is dependent on page length and number of templates/ref statements to be found -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9106a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"extimated total time:\", \n",
    "#       EXTIMATED_TOT_REVISIONS*ut.TEMP_TIMERS['whole_process']/(ut.TEMP_COUNTERS['_sources_extraction'])/60**2, 'hrs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6941d64e",
   "metadata": {},
   "source": [
    "<!-- With the sample of the first 40 page, I expect less time since the first one have more edits and more sources inside -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2853c4-6e07-4fa3-ac74-4f90cfbda827",
   "metadata": {},
   "source": [
    "Info to retain\n",
    "\n",
    "- **SECTION WHERE THE SOURCE IS USED?** Worthwile I guess\n",
    "- **WHAT TO DO WITH PAGES THAT ARE JUST REDIRECT?** Not worthwile I guess\n",
    "- flag some revision? can be done later \n",
    "- bot activity? can be done later\n",
    "\n",
    "Not clear to me (wiki api)\n",
    "\n",
    "- I do get 50 revision per request, while rvlim='max' is supposed to provide 500 (works with 500 for the wpp_to_n_revisions indeed)\n",
    "- Is there a request limit for wikipedia action API?\n",
    "Yes? https://api.wikimedia.org/wiki/Documentation/Getting_started/Rate_limits#Anonymous_requests \n",
    "- - Am I anonymus?\n",
    "- - is this rate limit applicable to this request?\n",
    "\n",
    "Better pipeline\n",
    "- Parallelization \n",
    "- Asyncronous process to save request time (around 20% time decrease)\n",
    "- sources2locs algorithm\n",
    "- - retrieve page differences before comparing versions?\n",
    "- - ignore somewhat bad revision? [generally no because that is a signal from a user] Maybe revisions flagged as \"minor\"? If we are sure that a source is not modified in minor revisions\n",
    "\n",
    "structured data:\n",
    "\n",
    "- urlsrv dataframe\n",
    "- - identifier of page (is it implicit in revision_id?)\n",
    "- - identifier of user (is it implicit in revision_id? Is it worth to de-structure it away?)\n",
    "- - identifier of revision\n",
    "- - identifier of url\n",
    "- - added/removed \n",
    "\n",
    "- Page data:\n",
    "- - identifier of page\n",
    "- - page id, page name\n",
    "- - whatever\n",
    "\n",
    "- User data:\n",
    "- - identifier of user\n",
    "- - user_id, username\n",
    "- - whatever\n",
    "\n",
    "- Revision data\n",
    "- - identifier of revision\n",
    "- - parent_id\n",
    "- - timestamp\n",
    "- - user?\n",
    "- - page?\n",
    "\n",
    "- URLS data:\n",
    "- - identifier of url\n",
    "- - url status\n",
    "- - domain\n",
    "- - destination_url\n",
    "- - destination_domain \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7035be-7ce0-441b-b9a1-d6f507f073ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
